{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-20T17:17:25.168179Z",
     "start_time": "2019-06-20T17:17:24.986130Z"
    },
    "id": "Hjp__3bRh42K",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Spring 2022 CS 4641\\7641 A: Machine Learning Homework 4\n",
    "\n",
    "## Instructor: Dr. Mahdi Roozbahani\n",
    "\n",
    "## Deadline: Thursday, April 21, 2022 11:59 pm AOE\n",
    "\n",
    "<!-- No changes needed on the below section -->\n",
    "* No unapproved extension of the deadline is allowed. Late submission will lead to 0 credit. \n",
    "\n",
    "* Discussion is encouraged on Ed as part of the Q/A. However, all assignments should be done individually.\n",
    "<font color='darkred'>\n",
    "* Plagiarism is a **serious offense**. You are responsible for completing your own work. You are not allowed to copy and paste, or paraphrase, or submit materials created or published by others, as if you created the materials. All materials submitted must be your own.</font>\n",
    "<font color='darkred'>\n",
    "* All incidents of suspected dishonesty, plagiarism, or violations of the Georgia Tech Honor Code will be subject to the instituteâ€™s Academic Integrity procedures. If we observe any (even small) similarities/plagiarisms detected by Gradescope or our TAs, **WE WILL DIRECTLY REPORT ALL CASES TO OSI**, which may, unfortunately, lead to a very harsh outcome. Consequences can be severe, e.g., academic probation or dismissal, grade penalties, a 0 grade for assignments concerned, and prohibition from withdrawing from the class.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSJJRXYL2yOY"
   },
   "source": [
    "## Instructions for the assignment \n",
    "\n",
    "<!-- No changes needed on the below section -->\n",
    "- This assignment consists of both programming and theory questions.\n",
    "\n",
    "- Unless a theory question explicitly states that no work is required to be shown,  you must provide an explanation, justification, or calculation for your answer.\n",
    "\n",
    "- To switch between cell for code and for markdown, see the menu -> Cell -> Cell Type\n",
    "    \n",
    "- You can directly type Latex equations into markdown cells.\n",
    "    \n",
    "- If a question requires a picture, you could use this syntax `<img src=\"\" style=\"width: 300px;\"/>` to include them within your ipython notebook.\n",
    "\n",
    "- Your write up must be submitted in PDF form. You may use either Latex,  markdown, or any word processing software. <font color = 'darkred'>We will **NOT** accept handwritten work. </font> Make sure that your work is formatted correctly, for example submit $\\sum_{i=0} x_i$ instead of \\text{sum\\_\\{i=0\\} x\\_i}\n",
    "- When submitting the non-programming part of your assignment, you must correctly map pages of your PDF to each question/subquestion to reflect where they appear. <font color='darkred'>**Improperly mapped questions may not be graded correctly and/or will result in point deductions for the error.**</font>\n",
    "- All assignments should be done individually, and each student must write up and submit their own answers.\n",
    "- **Graduate Students**: You are required to complete any sections marked as Bonus for Undergrads  \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nN-9x-Qm2yOY"
   },
   "source": [
    "## Using the autograder\n",
    "\n",
    "\n",
    "* You will find three assignments (for grads) on Gradescope that correspond to HW4: \"Assignment 4 Programming\", \"Assignment 4 - Non-programming\" and \"Assignment 4 Programming - Bonus for all\". Undergrads will have an additional assignment called \"Assignment 4 Programming - Bonus for Undergrads\". \n",
    "* You will submit your code for the autograder in the Assignment 4 Programming sections. Please refer to the Deliverables and Point Distribution section for what parts are considered required, bonus for undergrads, and bonus for all\".\n",
    "* We provided you different .py files and we added libraries in those files please DO NOT remove those lines and add your code after those lines. Note that these are the only allowed libraries that you can use for the homework \n",
    "* You are allowed to make as many submissions until the deadline as you like. Additionally, note that the autograder tests each function separately, therefore it can serve as a useful tool to help you debug your code if you are not sure of what part of your implementation might have an issue \n",
    "* For the \"Assignment 4 - Non-programming\" part, you will download your Jupyter Notebook as html and submit it as a PDF on Gradescope. To download the notebook as html, click on \"File\" on the top left corner of this page and select \"Download as > html\". Then, open the html file and print to PDF. Please refer to the Deliverables and Point Distribution section for an outline of the non-programming questions. \n",
    "* **When submitting to Gradescope, please make sure to mark the page(s) corresponding to each problem/sub-problem. The pages in the PDF should be of size 8.5\" x 11\", otherwise there may be a deduction in points for extra long sheets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverables and Points Distribution \n",
    "\n",
    "### Q1: Two Layer NN [65 pts; 50pts + 15pts Undergrad Bonus] \n",
    "#### Deliverables: <font color = 'green'>NN.py and Notebook Graphs</font>\n",
    "\n",
    "\n",
    "- **Implementation** [55pts; 45pts + 10pts Bonus for CS 4641] - _programming_\n",
    "\n",
    "    - relu [5pts]\n",
    "\n",
    "    - tanh [5pts]\n",
    "\n",
    "    - loss [5pts]\n",
    "\n",
    "    - forward [10pts]\n",
    "    \n",
    "    - backward [10pts]\n",
    "    \n",
    "    - Gradient Descent [10pts]\n",
    "    \n",
    "    - Batch Gradient Descent [10pts Bonus for CS 4641]\n",
    "\n",
    "- **Questions** [10pts: 5pts + 5pts Bonus for CS 4641] - _non-programming_\n",
    "\n",
    "    - Loss plot and MSE for Gradient Descent [5pts]\n",
    "\n",
    "    - Loss plot and MSE for Stochastic Gradient Descent [5pts Bonus for CS 4641]\n",
    "\n",
    "### Q2: CNN [15pts; 12pts Undergrad Bonus + 3pts Bonus for All]\n",
    "#### Deliverables: <font color = 'green'>cnn.py and Written Report</font>\n",
    "\n",
    "- 2.1.3 [2pts Bonus for CS 4641] - *programming*\n",
    "\n",
    "- 2.1.4 [8pts Bonus for CS 4641] - *non-programming*\n",
    "\n",
    "- 2.1.5 [2pts Bonus for CS 4641] - *non-programming*\n",
    "\n",
    "- 2.2   [3pts Bonus for All] - *non-programming*\n",
    "\n",
    "### Q3: Random Forest [50pts]\n",
    "#### Deliverables: <font color = 'green'>random_forest.py and Written Report</font>\n",
    "\n",
    "- 3.1 Random Forest Implementation [35pts] - *programming*\n",
    "\n",
    "- 3.2 Hyperparameter Tuning with a Random Forest [5pts] - *programming*\n",
    "\n",
    "- 3.3 Plotting Feature Importance [5pts] - *non-programming*\n",
    "\n",
    "- 3.4 Improvement [5pts] - *non-programming*\n",
    "\n",
    "### Q4: SVM [30pts Bonus for all]\n",
    "#### Deliverables: <font color = 'green'>feature.py and Written Report</font>\n",
    "\n",
    "- 4.1: Fitting an SVM Classifier by hand [20pts] - * non programming*\n",
    "\n",
    "- 4.2: Feature Mapping [10pts] - *programming*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7U0WVt07tGRv"
   },
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "o0Ui6T2as9iI"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from math import log2, sqrt\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mq4QZ4su2yOd"
   },
   "source": [
    "## 1: Two Layer Neural Network [70 pts; 55pts + 15pts Undergrad Bonus]  <span style=\"color:blue\">**[P]**</span><span style=\"color:blue\">**[W]**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "<img src=\"./images/NN_image.png\">\n",
    "\n",
    "<br><br>\n",
    "\n",
    "A single layer perceptron can be thought of as a linear hyperplane as in logistic regression followed by a non-linear activation function. $$u_{i} = \\sum \\limits_{j=1}^{d} \\theta_{ij}x_{j}+b_{i}$$  $$o_{i} = \\phi \\left( \\sum \\limits_{j=1}^{d} \\theta_{ij}x_{j}+b_{i} \\right) = \\phi(\\theta_{i}^{T}x+b_{i})$$ where $x$ is a d-dimensional vector i.e. $x \\in R^{d}$. It is one datapoint with $d$ features. $\\theta_{i} \\in R^{d}$ is the weight vector for the $i^{th}$ hidden unit, $b_{i} \\in R$ is the bias element for the $i^{th}$ hidden unit and $\\phi(.)$ is a non-linear activation function that has been described below. $u_{i}$ is a linear combination of the features in $x_j$ weighted by $\\theta_{i}$ whereas $o_{i}$ is the $i^{th}$ output unit from the activation layer. \n",
    "\n",
    "\n",
    "## Fully connected Layer\n",
    "Typically, a modern neural network contains millions of perceptrons as the one shown in the previous image. Perceptrons interact in different configurations such as cascaded or parallel. In this part, we describe a fully connected layer configuration in a neural network which comprises multiple parallel perceptrons forming one layer. \n",
    "\n",
    "We extend the previous notation to describe a fully connected layer. Each layer in a fully connected network has a number of input/hidden/output units cascaded in parallel. Let us a define a single layer of the neural net as follows: <br>\n",
    "$m$ demotes the number of hidden units in a single layer $l$ whereas $n$ denotes the number of units in the previous layer $l-1$.\n",
    "$$u^{[l]}=\\theta^{[l]}o^{[l-1]}+b^{[l]}$$ where $u^{[l]} \\in R^{m}$ is a m-dimensional vector pertaining to the hidden units of the $l^{th}$ layer of the neural network after applying linear operations. Similarly, $o^{[l-1]}$ is the n-dimensional output vector corresponding to the hidden units of the $(l-1)^{th}$ activation layer. $\\theta^{[l]} \\in R^{m \\times n}$ is the weight matrix of the $l^{th}$ layer where each row of $\\theta^{[l]}$ is analogous to $\\theta_{i}$ described in the previous section i.e. each row corresponds to one hidden unit of the $l^{th}$ layer. $b^{[l]} \\in R^{m}$ is the bias vector of the layer where each element of b pertains to one hidden unit of the $l^{th}$ layer. This is followed by element wise non-linear activation function $o^{[l]} = \\phi(u^{[l]})$.\n",
    "The whole operation can be summarized as,\n",
    "$$o^{[l]} = \\phi(\\theta^{[l]}o^{[l-1]}+b^{[l]}) $$\n",
    "where $o^{[l-1]}$ is the output of the previous layer. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Activation Function \n",
    "There are many activation functions in the literature but for this question we are going to use Relu and Tanh only. \n",
    "\n",
    "<span>**HINT 1: When calculating the tanh and relu function, make sure you are not modifying the values in the original passed in matrix. You may find np.copy() helpful (`u` should not be modified in the method.)**</span>\n",
    ".\n",
    "### Relu\n",
    "The rectified linear unit (Relu) is one of the most commonly used activation functions in deep learning models. The mathematical form is $$o = \\phi(u) = max(0,u)$$One of the advantages of Relu is that it is a fast nonlinearity. <br> The derivative of relu function is given as $o' = \\phi'(u) = \\begin{cases}\n",
    "&0& u \\leq 0 \\\\\n",
    "&1& u > 0\n",
    "\\end{cases} $  \n",
    "\n",
    "\n",
    "![Relu](https://drive.google.com/uc?id=1qFNOnhB3B0wgt56bMsc-WI6cX0UWJAQX)\n",
    "\n",
    "\n",
    "\n",
    "### Tanh\n",
    "Tanh also known as hyperbolic tangent is like a shifted version of sigmoid activation function with its range going from -1 to 1. Tanh almost always proves to be better than the sigmoid function since the mean of the activations are closer to zero. Tanh has an effect of centering data that makes learning for the next layer a bit easier. The mathematical form of tanh is given as $$o = \\phi(u) = tanh(u) = \\frac{e^{u} - e^{-u}}{e^{u} + e^{-u}}$$ The derivative of tanh is given as $$o' = \\phi'(u) = 1 - {\\left(\\frac{e^{u} - e^{-u}}{e^{u} + e^{-u}}\\right)}^{2} = 1 - o^{2}$$\n",
    "\n",
    "\n",
    "![Tanh](https://drive.google.com/uc?id=1FD83cZIsI1gY6g0dDKyaaHFrCnThl9za)\n",
    "\n",
    "\n",
    "### Sigmoid\n",
    "The sigmoid function is another non-linear function with S-shaped curve. This function is useful in the case of binary classification as its output is between 0 and 1. The mathematical form of the function is $$o = \\phi(u)=\\frac{1}{1+e^{-u}}$$<br> The derivation of the sigmoid function has a nice form and is given as $$o' = \\phi'(u) = \\frac{1}{1+e^{-u}} \\left(1-\\frac{1}{1+e^{-u}}\\right) = \\phi(u)(1-\\phi(u))$$\n",
    "<br><br>\n",
    "\n",
    "<b>Note:</b> We will not be using sigmoid activation function for this assignment. This is included only for the sake of completeness. \n",
    "\n",
    "\n",
    "\n",
    "![Sigmoid](https://drive.google.com/uc?id=19UPS1IfcVNqH_PMAPg6ymAAVqGo9zHle)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Mean Squared Error \n",
    "\n",
    "It is an estimator that measures the average of the squares of the errors i.e. the average squared difference between the actual and the estimated values. It estimates the quality of the learnt hypothesis between the actual and the predicted values. It's non-negative and closer to zero, the better the learnt function is.\n",
    "\n",
    "### Implementation details\n",
    "For regression problems as in this exercise, we compute the loss as follows:\n",
    "\n",
    "$$MSE = \\frac{1}{2N}\\sum\\limits_{i=1}^{N}\\left(y_{i} -  \\hat{y_{i}}\\right)^{2}$$\n",
    "where $y_{i}$ is the true label and $\\hat{y_{i}}$ is the estimated label. We use a factor of $\\frac{1}{2N}$ instead of $\\frac{1}{N}$ to simply the derivative of loss function. \n",
    "\n",
    "\n",
    "## Forward Propagation\n",
    "We start by initializing the weights of the fully connected layer using Xavier initialization [Xavier initialization](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) (At a high level, we are using a uniform distribution for weight initialization). During training, we pass all the data points through the network layer by layer using forward propagation. The main equations for forward prop have been described below. \n",
    "\\begin{eqnarray}\n",
    "u^{[0]} &=& x\\\\\n",
    "u^{[1]}&=& \\theta^{[1]}u^{[0]}+b^{[1]} \\\\\n",
    "o^{[1]}&=& Relu(u^{[1]}) \\\\\n",
    "u^{[2]}&=& \\theta^{[2]}o^{[1]}+b^{[2]} \\\\\n",
    "\\hat{y}=o^{[2]}&=& Tanh(u^{[2]}) \\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "Then we get the output and compute the loss \n",
    "$$l = \\frac{1}{2N}\\sum\\limits_{i=1}^{N}\\left(y_{i} -  \\hat{y_{i}}\\right)^{2}$$\n",
    "\n",
    "\n",
    "## Backward propagation\n",
    "After the forward pass, we do back propagation to update the weights and biases in the direction of the negative gradient of the loss function. So, we update the weights and biases using the following formulas\n",
    "\\begin{equation}\n",
    "\\theta^{[2]} := \\theta^{[2]} - lr \\times \\frac{\\partial l}{\\partial \\theta^{[2]}} \\\\\n",
    "b^{[2]} := b^{[2]} - lr \\times \\frac{\\partial l}{\\partial b^{[2]}} \\\\\n",
    "\\theta^{[1]} := \\theta^{[1]} - lr \\times \\frac{\\partial l}{\\partial \\theta^{[1]}} \\\\\n",
    "b^{[1]} := b^{[1]} - lr \\times \\frac{\\partial l}{\\partial b^{[1]}}\n",
    "\\end{equation}\n",
    "where $lr$ is the learning rate. It decides the step size we want to take in the direction of the negative gradient. \n",
    "\n",
    "\n",
    "\n",
    "To compute the terms $\\frac{\\partial l}{\\partial \\theta^{[i]}}$ and $ \\frac{\\partial l}{\\partial b^{[i]}}$ we use chain rule for differentiation as follows:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial l}{\\partial \\theta^{[2]}}&=&\\frac{\\partial l}{\\partial o^{[2]}}\\frac{\\partial o^{[2]}}{\\partial u^{[2]}}\\frac{\\partial u^{[2]}}{\\partial \\theta^{[2]}} \\\\\n",
    "\\frac{\\partial l}{\\partial b^{[2]}}&=&\\frac{\\partial l}{\\partial o^{[2]}}\\frac{\\partial o^{[2]}}{\\partial u^{[2]}}\\frac{\\partial u^{[2]}}{\\partial b^{[2]}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "So, $\\frac{\\partial l}{\\partial o^{[2]}}$ is the differentiation of the loss function at point $o^{[2]}$ <br><br> $\\frac{\\partial o^{[2]}}{\\partial u^{[2]}}$ is the differentiation of the Tanh function at point $u^{[2]}$ <br><br> $\\frac{\\partial u^{[2]}}{\\partial \\theta^{[2]}}$ is equal to $o^{[1]}$ <br><br> $\\frac{\\partial u^{[2]}}{\\partial b^{[2]}}$ is equal to $1$. <br><br>\n",
    "\n",
    "To compute $\\frac{\\partial l}{\\partial \\theta^{[2]}}$, we need $o^{[2]}, u^{[2]} \\& o^{[1]}$ which are calculated during forward propagation. So we need to store these values in cache variables during forward propagation to be able to access them during backward propagation. Similarly for calculating other partial derivatives, we store the values we'll be needing for chain rule in cache. These values are obtained from the forward propagation and used in backward propagation. The cache is implemented as a dictionary here where the keys are the variable names and the values are the variables values.  <br><br>Also, the functional form of the MSE differentiation and Relu differentiation are given by <br><br>\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial l}{\\partial o^{[2]}} &=& \\left(o^{[2]} - y\\right) \\\\\n",
    "\\frac{\\partial l}{\\partial u^{[2]}} &=&  \\frac{\\partial l}{\\partial o^{[2]}} * (1 - (tanh(u^{[2]}))^2)\\\\\n",
    "\\frac{\\partial u^{[2]}}{\\partial \\theta^{[2]}} &=& o^{[1]} \\\\\n",
    "\\frac{\\partial u^{[2]}}{\\partial b^{[2]}} &=& 1\n",
    "\\end{eqnarray}\n",
    "\n",
    "On vectorization, the above equations become:\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial l}{\\partial o^{[2]}} &=& \\frac{1}{n}\\left(o^{[2]} - y\\right) \\\\\n",
    "\\frac{\\partial l}{\\partial \\theta^{[2]}} &=&  \\frac{1}{n}\\frac{\\partial l}{\\partial u^{[2]}}o^{[1]} \\\\\n",
    "\\frac{\\partial l}{\\partial b^{[2]}} &=& \\frac{1}{n}\\sum\\frac{\\partial l}{\\partial u^{[2]}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "<span>**HINT 2: Division by $N$ only needs to occur ONCE for any derivative that requires a division by $N$. Make sure you avoid cascading divisions by $N$ where you might accidentally divide your derivative by $N^2$ or greater.**</span>\n",
    "\n",
    "This completes the differentiation of loss function w.r.t to parameters in the second layer. We now move on to the first layer, the equations for which are given as follows: <br><br> \n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial l}{\\partial \\theta^{[1]}}&=&\\frac{\\partial l}{\\partial o^{[2]}}\\frac{\\partial o^{[2]}}{\\partial u^{[2]}}\\frac{\\partial u^{[2]}}{\\partial o^{[1]}} \\frac{\\partial o^{[1]}}{\\partial u^{[1]}} \\frac{\\partial u^{[1]}}{\\partial \\theta^{[1]}}  \\\\\n",
    "\\frac{\\partial l}{\\partial b^{[1]}}&=&\\frac{\\partial l}{\\partial o^{[2]}}\\frac{\\partial o^{[2]}}{\\partial u^{[2]}}\\frac{\\partial u^{[2]}}{\\partial o^{[1]}} \\frac{\\partial o^{[1]}}{\\partial u^{[1]}} \\frac{\\partial u^{[1]}}{\\partial b^{[1]}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "Where \n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial u^{[2]}}{\\partial o^{[1]}} &=& \\theta^{[2]} \\\\\n",
    "\\frac{\\partial o^{[1]}}{\\partial u^{[1]}} &=& 1(o^{[1]} > 0)\\\\\n",
    "\\frac{\\partial u^{[1]}}{\\partial \\theta^{[1]}} &=& x\\\\\n",
    "\\frac{\\partial u^{[1]}}{\\partial b^{[1]}} &=& 1\n",
    "\\end{eqnarray}\n",
    "\n",
    "Note that $\\frac{\\partial o^{[1]}}{\\partial u^{[1]}}$ is the differentiation of the ReLU function at $u^{[1]}$.\n",
    "\n",
    "The above equations outline the forward and backward propagation process for a 2-layer fully connected neural net with Relu as the first activation layer and Tanh has the second one. The same process can be extended to different neural networks with different activation layers. \n",
    "\n",
    "\n",
    "\n",
    "## Code Implementation: \n",
    "\n",
    "$$ \\begin{eqnarray} dLoss\\_o2 &=& \\frac{\\partial l}{\\partial o^{[2]}} \\implies dim=(1,375) \\\\ dLoss\\_u2 &=& dLoss\\_o2 \\frac{\\partial o^{[2]}}{\\partial u^{[2]}} \\implies dim=(1,375) \\\\ dLoss\\_theta2 &=& dLoss\\_u2 \\frac{\\partial u^{[2]}}{\\partial \\theta^{[2]}} \\implies dim=(1,15) \\\\ dLoss\\_b2 &=& dLoss\\_u2 \\frac{\\partial u^{[2]}}{\\partial b^{[2]}} \\implies dim=(1,1) \\\\ dLoss\\_o1 &=& dLoss\\_u2 \\frac{\\partial u^{[2]}}{\\partial o^{[1]}} \\implies dim=(15,375) \\\\ dLoss\\_u1 &=& dLoss\\_o1 \\frac{\\partial o^{[1]}}{\\partial u^{[1]}} \\implies dim=(15,375) \\\\ dLoss\\_theta1 &=& dLoss\\_u1 \\frac{\\partial u^{[1]}}{\\partial \\theta^{[1]}} \\implies dim=(15,8) \\\\ dLoss\\_b1 &=& dLoss\\_u1 \\frac{\\partial u^{[1]}}{\\partial b^{[1]}} \\implies dim=(15,1) \\end{eqnarray} $$ \n",
    "\n",
    "\n",
    "<b>Note: </b>Training set has 375 examples.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question \n",
    "\n",
    "In this question, you will implement a two layer fully connected neural network. You will also experiment with different activation functions and optimization techniques. Functions with comments \"TODO: implement this\" are for you to implement. We provide two activation functions here - Relu and Tanh. You will implement a neural network that would have Relu activation followed by a Tanh layer. \n",
    "\n",
    "You'll also implement Gradient Descent (GD) and Batch Gradient Descent (BGD) algorithms for training these neural nets. **GD is mandatory for all. BGD is bonus for undergraduate students but mandatory for graduate students.** \n",
    "\n",
    "In the <strong>NN.py</strong> file, complete the following functions:\n",
    "  * <strong>Relu</strong>: Recall Hint 1\n",
    "  * <strong>Tanh</strong>: Recall Hint 1\n",
    "  * <strong>nloss</strong>\n",
    "  * <strong>forward</strong>\n",
    "  * <strong>backward</strong>: Recall Hint 2\n",
    "  * <strong>gradient_descent</strong>\n",
    "  * <strong>batch_gradient_descent</strong>:<span style=\"color:darkred\"> **Mandatory for graduate students, bonus for undergraduate students.**</span> Please batch your data in a wraparound manner. For example, given a dataset of 9 numbers, [1, 2, 3, 4, 5, 6, 7, 8, 9], and a batch size of 6, the first iteration batch will be [1, 2, 3, 4, 5, 6], the second iteration batch will be [7, 8, 9, 1, 2, 3], the third iteration batch will be [4, 5, 6, 7, 8, 9], etc... \n",
    "\n",
    "We'll train this neural net on sklearn's California housing dataset. Graduate students have to use both GD and BGD to optimize their neural net. Undergraduate students have to implement GD while BGD is bonus for them.  Note: it is possible you'll run into nan or negative values for loss. This happens because of some numerical stability issues that arise due to division by zero, natural log of zeros etc. You can experiment with the total number of iterations to mitigate this. \n",
    "\n",
    "You're free to tune hyperparameters like the batch size, number of hidden units in each layer etc. if that helps you in achieving the desired MSE values to pass the autograder tests. However, you're advised to try out the default values first. \n",
    "\n",
    "\n",
    "<b>Deliverables for this question: </b>\n",
    "1. Loss plot and MSE value for neural net with gradient descent \n",
    "2. Loss plot and MSE value for neural net with batch gradient descent (mandatory for graduate students, bonus for undergraduate students)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0 loss:  0.06580578498250138\n",
      "iteration:  1000 loss:  0.023205614446277716\n",
      "iteration:  2000 loss:  0.01861208160724238\n",
      "iteration:  3000 loss:  0.016591511370856186\n",
      "iteration:  4000 loss:  0.015852072834058206\n",
      "iteration:  5000 loss:  0.015462203438163787\n",
      "iteration:  6000 loss:  0.01519195285476188\n",
      "iteration:  7000 loss:  0.014973320889456517\n",
      "iteration:  8000 loss:  0.014783904241880502\n",
      "iteration:  9000 loss:  0.014609356571820801\n",
      "iteration:  10000 loss:  0.014441955428294231\n",
      "iteration:  11000 loss:  0.014279513971834648\n",
      "iteration:  12000 loss:  0.014119707751303471\n",
      "iteration:  13000 loss:  0.013969949745068806\n",
      "iteration:  14000 loss:  0.013818913820035103\n",
      "iteration:  15000 loss:  0.013677562091034485\n",
      "iteration:  16000 loss:  0.013541724061220051\n",
      "iteration:  17000 loss:  0.013416187629710967\n",
      "iteration:  18000 loss:  0.013286664004858742\n",
      "iteration:  19000 loss:  0.013161035888453576\n",
      "iteration:  20000 loss:  0.013037381054948718\n",
      "iteration:  21000 loss:  0.012918546562239319\n",
      "iteration:  22000 loss:  0.012801545901069437\n",
      "iteration:  23000 loss:  0.01268719694135431\n",
      "iteration:  24000 loss:  0.012577595212727256\n",
      "iteration:  25000 loss:  0.01247369053390475\n",
      "iteration:  26000 loss:  0.012372132864200582\n",
      "iteration:  27000 loss:  0.012273117802558336\n",
      "iteration:  28000 loss:  0.012177470764056645\n",
      "iteration:  29000 loss:  0.012084243792504102\n",
      "iteration:  30000 loss:  0.01198909151453105\n",
      "iteration:  31000 loss:  0.011897629668524187\n",
      "iteration:  32000 loss:  0.011812203946524751\n",
      "iteration:  33000 loss:  0.011730511707522661\n",
      "iteration:  34000 loss:  0.011654688339757652\n",
      "iteration:  35000 loss:  0.011581326740862648\n",
      "iteration:  36000 loss:  0.011509785956259582\n",
      "iteration:  37000 loss:  0.011440633084831574\n",
      "iteration:  38000 loss:  0.01137366598637797\n",
      "iteration:  39000 loss:  0.011307683458970057\n",
      "iteration:  40000 loss:  0.011241816146067047\n",
      "iteration:  41000 loss:  0.011178069621438965\n",
      "iteration:  42000 loss:  0.011116454958485714\n",
      "iteration:  43000 loss:  0.011057392205881195\n",
      "iteration:  44000 loss:  0.011000149273891261\n",
      "iteration:  45000 loss:  0.01094506531815658\n",
      "iteration:  46000 loss:  0.010891283448021464\n",
      "iteration:  47000 loss:  0.010838881958746356\n",
      "iteration:  48000 loss:  0.010788413206524456\n",
      "iteration:  49000 loss:  0.01073858666147458\n",
      "iteration:  50000 loss:  0.010690307025300853\n",
      "iteration:  51000 loss:  0.010643703167525788\n",
      "iteration:  52000 loss:  0.010598217994695451\n",
      "iteration:  53000 loss:  0.010554332865147856\n",
      "iteration:  54000 loss:  0.010511802169665711\n",
      "iteration:  55000 loss:  0.010470307063622755\n",
      "iteration:  56000 loss:  0.010429908579169346\n",
      "iteration:  57000 loss:  0.010390488635361914\n",
      "iteration:  58000 loss:  0.010351807073766227\n",
      "iteration:  59000 loss:  0.010314216157286052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from NN import dlnet\n",
    "\n",
    "dataset = fetch_california_housing() # load the dataset\n",
    "x, y = dataset.data, dataset.target\n",
    "y = y.reshape(-1,1)\n",
    "perm = np.random.RandomState(seed=3).permutation(x.shape[0])[:500]\n",
    "x = x[perm]\n",
    "y = y[perm]\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1) #split data\n",
    "\n",
    "\n",
    "x_scale = MinMaxScaler()\n",
    "x_train = x_scale.fit_transform(x_train) #normalize data\n",
    "x_test = x_scale.transform(x_test) \n",
    "\n",
    "y_scale = MinMaxScaler()\n",
    "y_train = y_scale.fit_transform(y_train)\n",
    "y_test = y_scale.transform(y_test)\n",
    "\n",
    "x_train, x_test, y_train, y_test = x_train.T, x_test.T, y_train.reshape(1,-1), y_test #condition data\n",
    "\n",
    "nn = dlnet(x_train,y_train,lr=0.01) # initalize neural net class\n",
    "nn.gradient_descent(x_train, y_train, iter = 60000) #train\n",
    "\n",
    "# create figure\n",
    "fig = plt.plot(np.array(nn.loss).squeeze())\n",
    "plt.title(f'Training: {nn.neural_net_type}')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) 0.019041105174635805\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "y_predicted = nn.predict(x_test) # predict\n",
    "y_test = y_test.reshape(1,-1)\n",
    "print(\"Mean Squared Error (MSE)\", (np.sum((y_predicted-y_test)**2)/y_test.shape[1]))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 375\n",
      "iteration:  0 loss:  0.06605742450877064\n",
      "iteration:  1000 loss:  0.029533317352058937\n",
      "iteration:  2000 loss:  0.021880667085131686\n",
      "iteration:  3000 loss:  0.012228476374490987\n",
      "iteration:  4000 loss:  0.021473848392620492\n",
      "iteration:  5000 loss:  0.018316291455794935\n",
      "iteration:  6000 loss:  0.01146777093629291\n",
      "iteration:  7000 loss:  0.020541404284057995\n",
      "iteration:  8000 loss:  0.0174028770304618\n",
      "iteration:  9000 loss:  0.011211024010674472\n",
      "iteration:  10000 loss:  0.019816322979924302\n",
      "iteration:  11000 loss:  0.016771252987169045\n",
      "iteration:  12000 loss:  0.010973238942220095\n",
      "iteration:  13000 loss:  0.01911558540498066\n",
      "iteration:  14000 loss:  0.016246869820478835\n",
      "iteration:  15000 loss:  0.010712350809874972\n",
      "iteration:  16000 loss:  0.018526977331921962\n",
      "iteration:  17000 loss:  0.015828926600347015\n",
      "iteration:  18000 loss:  0.010485212434889021\n",
      "iteration:  19000 loss:  0.018055234062586266\n",
      "iteration:  20000 loss:  0.015399722046244069\n",
      "iteration:  21000 loss:  0.010289772581266479\n",
      "iteration:  22000 loss:  0.017642079094444173\n",
      "iteration:  23000 loss:  0.015028450430393348\n",
      "iteration:  24000 loss:  0.010130426102481792\n",
      "iteration:  25000 loss:  0.017241961922307543\n",
      "iteration:  26000 loss:  0.014681906800392178\n",
      "iteration:  27000 loss:  0.00999916543028865\n",
      "iteration:  28000 loss:  0.01687584047709092\n",
      "iteration:  29000 loss:  0.014356844157668013\n",
      "iteration:  30000 loss:  0.009886617855614194\n",
      "iteration:  31000 loss:  0.01654183311794028\n",
      "iteration:  32000 loss:  0.014013833291492597\n",
      "iteration:  33000 loss:  0.009799871192837959\n",
      "iteration:  34000 loss:  0.01623273545478713\n",
      "iteration:  35000 loss:  0.013727056130133005\n",
      "iteration:  36000 loss:  0.009741702554807734\n",
      "iteration:  37000 loss:  0.01593899443268708\n",
      "iteration:  38000 loss:  0.01346079606478551\n",
      "iteration:  39000 loss:  0.00969430843745437\n",
      "iteration:  40000 loss:  0.015692809975832094\n",
      "iteration:  41000 loss:  0.013217751907927972\n",
      "iteration:  42000 loss:  0.009615741185017124\n",
      "iteration:  43000 loss:  0.015452782926130348\n",
      "iteration:  44000 loss:  0.01298181838048098\n",
      "iteration:  45000 loss:  0.009575741522706127\n",
      "iteration:  46000 loss:  0.015219961024647908\n",
      "iteration:  47000 loss:  0.012759421090203543\n",
      "iteration:  48000 loss:  0.00953094224161952\n",
      "iteration:  49000 loss:  0.014999191694880815\n",
      "iteration:  50000 loss:  0.012542589205001368\n",
      "iteration:  51000 loss:  0.009503367680650177\n",
      "iteration:  52000 loss:  0.014800388892533385\n",
      "iteration:  53000 loss:  0.012353164280769623\n",
      "iteration:  54000 loss:  0.00947175665589856\n",
      "iteration:  55000 loss:  0.014625246131358129\n",
      "iteration:  56000 loss:  0.01217690409154929\n",
      "iteration:  57000 loss:  0.009450011758603966\n",
      "iteration:  58000 loss:  0.014459654633629514\n",
      "iteration:  59000 loss:  0.012001964288691935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from NN import dlnet\n",
    "\n",
    "dataset = fetch_california_housing() # load the dataset\n",
    "x, y = dataset.data, dataset.target\n",
    "y = y.reshape(-1,1)\n",
    "perm = np.random.RandomState(seed=3).permutation(x.shape[0])[:500]\n",
    "x = x[perm]\n",
    "y = y[perm]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1) #split data\n",
    "\n",
    "x_scale = MinMaxScaler()\n",
    "x_train = x_scale.fit_transform(x_train) #normalize data\n",
    "x_test = x_scale.transform(x_test) \n",
    "\n",
    "y_scale = MinMaxScaler()\n",
    "y_train = y_scale.fit_transform(y_train)\n",
    "y_test = y_scale.transform(y_test)\n",
    "\n",
    "x_train, x_test, y_train, y_test = x_train.T, x_test.T, y_train.reshape(1,-1), y_test #condition data\n",
    "\n",
    "nn = dlnet(x_train,y_train,lr=0.01) # initalize neural net class\n",
    "nn.batch_gradient_descent(x_train, y_train, iter = 60000) #train\n",
    "\n",
    "\n",
    "# create figure\n",
    "fig = plt.plot(np.array(nn.loss).squeeze())\n",
    "plt.title(f'Training: {nn.neural_net_type}')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) 0.019014642903062866\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "y_predicted = nn.predict(x_test) # predict \n",
    "y_test = y_test.reshape(1,-1)\n",
    "print(\"Mean Squared Error (MSE)\", (np.sum((y_predicted-y_test)**2)/y_test.shape[1]))\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayv_tqnyxMb0"
   },
   "source": [
    "## 2: Image Classification based on Convolutional Neural Networks [15pts total = 12pts Bonus for Undergrad + 3pts Bonus for all] <span style=\"color:green\">**[W]**</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NAcYa40pm86P"
   },
   "source": [
    " Keras is a deep learning API written in Python, running on top of the machine learning platform TensorFlow. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result as fast as possible is key to doing good research. In this part, you will build a convolutional neural network based on TF/Keras to solve the image classification task for the fashion mnist dataset. If you haven't installed TensorFlow, you can install the package by **pip** command or train your model by uploading HW4 notebook to [Colab](https://colab.research.google.com/) directly. Colab contains all packages you need for this section.  \n",
    "\n",
    "Hint1: [First contact with Keras](https://keras.io/about/)\n",
    "\n",
    "Hint2: [How to Install Keras](https://www.pyimagesearch.com/2016/07/18/installing-keras-for-deep-learning/)\n",
    "\n",
    "Hint3ï¼š[CS231n Tutorial (Layers used to build ConvNets) ](https://cs231n.github.io/convolutional-networks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWSeZNmCm86P"
   },
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "X2Cwef24xgtT"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: dlopen(/Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 0x0006): tried: '/Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e'))\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py:58\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py?line=55'>56</a>\u001b[0m   sys\u001b[39m.\u001b[39msetdlopenflags(_default_dlopen_flags \u001b[39m|\u001b[39m ctypes\u001b[39m.\u001b[39mRTLD_LOCAL)\n\u001b[0;32m---> <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py?line=57'>58</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpywrap_tensorflow_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py?line=58'>59</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpywrap_tensorflow_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n",
      "File \u001b[0;32m~/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow_internal.py:28\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow_internal.py?line=26'>27</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _mod\n\u001b[0;32m---> <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow_internal.py?line=27'>28</a>\u001b[0m _pywrap_tensorflow_internal \u001b[39m=\u001b[39m swig_import_helper()\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow_internal.py?line=28'>29</a>\u001b[0m \u001b[39mdel\u001b[39;00m swig_import_helper\n",
      "File \u001b[0;32m~/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow_internal.py:24\u001b[0m, in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow_internal.py?line=22'>23</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow_internal.py?line=23'>24</a>\u001b[0m     _mod \u001b[39m=\u001b[39m imp\u001b[39m.\u001b[39;49mload_module(\u001b[39m'\u001b[39;49m\u001b[39m_pywrap_tensorflow_internal\u001b[39;49m\u001b[39m'\u001b[39;49m, fp, pathname, description)\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow_internal.py?line=24'>25</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py:243\u001b[0m, in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py?line=241'>242</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py?line=242'>243</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m load_dynamic(name, filename, file)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py?line=243'>244</a>\u001b[0m \u001b[39melif\u001b[39;00m type_ \u001b[39m==\u001b[39m PKG_DIRECTORY:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py:343\u001b[0m, in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py?line=340'>341</a>\u001b[0m spec \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mmachinery\u001b[39m.\u001b[39mModuleSpec(\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py?line=341'>342</a>\u001b[0m     name\u001b[39m=\u001b[39mname, loader\u001b[39m=\u001b[39mloader, origin\u001b[39m=\u001b[39mpath)\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py?line=342'>343</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _load(spec)\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 0x0006): tried: '/Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/sankalpsangle/Desktop/HW4/HW4_Spring2022_Student.ipynb Cell 17'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sankalpsangle/Desktop/HW4/HW4_Spring2022_Student.ipynb#ch0000016?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sankalpsangle/Desktop/HW4/HW4_Spring2022_Student.ipynb#ch0000016?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sankalpsangle/Desktop/HW4/HW4_Spring2022_Student.ipynb#ch0000016?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m fashion_mnist\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sankalpsangle/Desktop/HW4/HW4_Spring2022_Student.ipynb#ch0000016?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[0;32m~/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/__init__.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/__init__.py?line=20'>21</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_os\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/__init__.py?line=22'>23</a>\u001b[0m \u001b[39m# pylint: disable=g-bad-import-order\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/__init__.py?line=23'>24</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow  \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/__init__.py?line=25'>26</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/__init__.py?line=26'>27</a>\u001b[0m   \u001b[39m# Add `estimator` attribute to allow access to estimator APIs via\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/__init__.py?line=27'>28</a>\u001b[0m   \u001b[39m# \"tf.estimator...\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/__init__.py?line=28'>29</a>\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mestimator\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m estimator  \u001b[39m# pylint: disable=g-import-not-at-top\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/__init__.py:49\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/__init__.py?line=31'>32</a>\u001b[0m \u001b[39m# TODO(drpng): write up instructions for editing this file in a doc and point to\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/__init__.py?line=32'>33</a>\u001b[0m \u001b[39m# the doc instead.\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/__init__.py?line=33'>34</a>\u001b[0m \u001b[39m# If you want to edit this file to expose modules in public tensorflow API, you\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/__init__.py?line=43'>44</a>\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/__init__.py?line=44'>45</a>\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/__init__.py?line=46'>47</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/__init__.py?line=48'>49</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/__init__.py?line=50'>51</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m component_api_helper\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/__init__.py?line=51'>52</a>\u001b[0m component_api_helper\u001b[39m.\u001b[39mpackage_hook(\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/__init__.py?line=52'>53</a>\u001b[0m     parent_package_str\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow.python\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/__init__.py?line=53'>54</a>\u001b[0m     child_package_str\u001b[39m=\u001b[39m(\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/__init__.py?line=54'>55</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtensorflow_estimator.python.estimator\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py:74\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py?line=68'>69</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py?line=69'>70</a>\u001b[0m   msg \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[39m\\n\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py?line=70'>71</a>\u001b[0m \u001b[39mSee https://www.tensorflow.org/install/errors\u001b[39m\u001b[39m\\n\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py?line=71'>72</a>\u001b[0m \u001b[39mfor some common reasons and solutions.  Include the entire stack trace\u001b[39m\n\u001b[1;32m     <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py?line=72'>73</a>\u001b[0m \u001b[39mabove this error message when asking for help.\u001b[39m\u001b[39m\"\"\"\u001b[39m \u001b[39m%\u001b[39m traceback\u001b[39m.\u001b[39mformat_exc()\n\u001b[0;32m---> <a href='file:///Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py?line=73'>74</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: dlopen(/Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 0x0006): tried: '/Users/sankalpsangle/Desktop/ML_Test/MLEnv/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e'))\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5wmr3mt2yOu"
   },
   "source": [
    "### 2.1.1 Load fashion mnist dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PxDuP6Yq2yOv"
   },
   "source": [
    "We use fashion mnist dataset to train our model. This is a dataset of 60,000 28x28 training images and 10,000 test images, labeled over 10 categories. Each example is $28\\times 28$ pixel grayscale image of various clothing items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zv8fRYkp2yOv",
    "outputId": "a8884fe7-a4f6-42e8-dfa7-b86b83c76349"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# split data between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "number_channels = 1\n",
    "#set num of classes\n",
    "num_classes = 10\n",
    "\n",
    "if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], number_channels, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], number_channels, img_rows, img_cols)\n",
    "    input_shape = (number_channels, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, number_channels)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, number_channels)\n",
    "    input_shape = (img_rows, img_cols, number_channels)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "fashion_classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IropaXmi2yOy"
   },
   "source": [
    "### 2.1.2 Load some sample images from fashion mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaUQz7x52yOy",
    "outputId": "fe6cb811-a827-4f91-b89f-6b14b416d8f8"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# Show some images from fashion_mnist\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "for i in range(50):\n",
    "    random_index = np.random.randint(0, len(y_train))\n",
    "    ax = fig.add_subplot(5, 10, i+1)\n",
    "    ax.imshow(x_train[random_index, :].squeeze(2), cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJEjYyism86Y"
   },
   "source": [
    "As you can see from above, the fashion mnist dataset contains a selection of fashion objects. The images have been size-normalized and objects remain centered in fixed-size images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deWtvYFKm86Z"
   },
   "source": [
    "### 2.1.3 Build convolutional neural network model [2pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8ioOgl1m86Z"
   },
   "source": [
    "In this part, you need to build a convolutional neural network as described below. All coding should be done in cnn.py. The architecture of the model is:\n",
    "\n",
    " **[INPUT - CONV - CONV - MAXPOOL - DROPOUT - CONV - CONV - MAXPOOL - DROPOUT - FC1 - DROPOUT - FC2]**\n",
    "\n",
    "> INPUT: [$28\\times28\\times1$] will hold the raw pixel values of the image, in this case, an image of width 28, height 28. This layer should give  8 filters and have appropriate padding to maintain shape.\n",
    "\n",
    "> CONV: Conv. layer will compute the output of neurons that are connected to local regions in the input, each computing a dot product between their weights and a small region they are connected to the input volume. We decide to set the kernel_size $3\\times3$ for the both Conv. layers. For example, the output of the Conv. layer may look like $[28\\times28\\times32]$ if we use 32 filters. Again, we use padding to maintain shape.\n",
    "\n",
    "> MAXPOOL: MAXPOOL layer will perform a downsampling operation along the spatial dimensions (width, height). With pool size of $2\\times2$, resulting shape takes form $14\\times14$.\n",
    "\n",
    "> DROPOUT: DROPOUT layer with the dropout rate of 0.30, to prevent overfitting.\n",
    "\n",
    "> CONV: Additonal Conv. layer take outputs from above layers and applies more filters. The Conv. layer may look like $[14\\times14\\times32]$. We set the kernel_size $3\\times3$ and use padding to maintain shape for both Conv. layers.\n",
    "\n",
    "> CONV: Additonal Conv. layer take outputs from above layers and applies more filters. The Conv. layer may look like $[14\\times14\\times64]$.\n",
    "\n",
    "> MAXPOOL: MAXPOOL layer will perform a downsampling operation along the spatial dimensions (width, height).\n",
    "\n",
    "> DROPOUT: Dropout layer with the dropout rate of 0.30, to prevent overfitting.\n",
    "\n",
    "> FC1: Dense layer which takes input above layers, and has 256 neurons. Flatten operations may be useful.\n",
    "\n",
    "> DROPOUT: Dropout layer with the dropout rate of 0.5, to prevent overfitting.\n",
    "\n",
    "> FC2: Dense layer with 10 neurons, and softmax activation, is the final layer. The dimension of the output space is the number of classes.\n",
    "\n",
    "**Activation function**:Use LeakyReLU with negative_slope 0.1 unless otherwise indicated to build you model architecture\n",
    "\n",
    "\n",
    "Note that while this is a suggested model design, you may use other architectures and experiment with different layers for better results.\n",
    "\n",
    "Use the following keras links to reference crucial layers of the model in keras API:\n",
    "\n",
    "- Conv2d: https://keras.io/api/layers/convolution_layers/convolution2d/\n",
    "- Dense: https://keras.io/api/layers/core_layers/dense/\n",
    "- Flatten: https://keras.io/api/layers/reshaping_layers/flatten/\n",
    "- MaxPool: https://keras.io/api/layers/pooling_layers/max_pooling2d/\n",
    "- Dropout: https://keras.io/api/layers/regularization_layers/dropout/\n",
    "\n",
    "And explore the keras layers API if you would like to experiment with additional layers: https://keras.io/api/layers/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6fLE8Wpm86Z",
    "outputId": "e3bde7b8-cf2f-4f25-bb8b-2d8adcf4f9b6"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# Show the architecture of the model\n",
    "achi=plt.imread('./images/Architecture.png')\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.imshow(achi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FagsUubm86c"
   },
   "source": [
    "#### Defining Variables ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now need to set training variebles in the __init__() function in cnn.py. Once you have defined variables you may use the cell below to see them.\n",
    "\n",
    "- Recommended Batch Sizes fall in the range 16-256 (use powers of 2)\n",
    "\n",
    "- Recommended Epoch Counts fall in the range 3-12\n",
    "\n",
    "- Recommended Learning Rates fall in the range .0001-.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RZp2AB_r2yO0"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-300c92c113d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# You can adjust parameters to train your model in __init__() in cnn.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/HW4/cnn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# You can adjust parameters to train your model in __init__() in cnn.py\n",
    "\n",
    "from cnn import CNN\n",
    "\n",
    "net = CNN()\n",
    "batch_size, epochs, init_lr = net.get_vars()\n",
    "print(f'Batch Size\\t: {batch_size} \\nEpochs\\t\\t: {epochs} \\nLearning Rate\\t: {init_lr} \\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5F5PWx17m86g"
   },
   "source": [
    "#### Defining model ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now need to complete the create_net() function in cnn.py to define your model structure. Once you have defined a model structure you may use the cell below to examine your architecture.\n",
    "\n",
    "Your model is required to have at least 2 convolutional layers and at least 2 dense layers. ensuring that these reqirements are met will earn you 2pts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKpTMi2rm86i",
    "outputId": "0082a080-9992-4b04-d721-ca0eb29f074a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# model.summary() gives you details of your architecture.\n",
    "#You can compare your architecture with the 'Architecture.png'\n",
    "\n",
    "from cnn import CNN\n",
    "net = CNN()\n",
    "\n",
    "s = tf.keras.backend.clear_session()\n",
    "model=net.create_net()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling model ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next prepare the model for training by completing compile_model() in cnn.py\n",
    "Remember we are performing 10-way clasification when selecting a loss function. Loss function can be categorical crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# Complete compile_model() in cnn.py.\n",
    "from cnn import CNN\n",
    "net = CNN()\n",
    "model = net.compile_net(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85m3oJ-1Voxe"
   },
   "source": [
    "### 2.1.4 Train the network [8pts total (3pts, 3pts, 2pts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYHAZAnZm86l"
   },
   "source": [
    "**Tuning:** Training the network is the next thing to try.  You can set your parameter at the **Defining Variable** section. If your parameters are set properly, you should see the loss of the validation set decreased and the value of accuracy increased. It may take more than 15 minutes to train your model. \n",
    "\n",
    "**Expected Result:** You should be able to achieve more than $90\\%$ accuracy on the test set to get full 12 points. If you achieve accuracy between $70\\%$ to $80\\%$, you will only get 3 points. An accuracy between $80\\%$ to $90\\%$ will earn an additional 3pts.\n",
    "\n",
    "- $70\\%$ to $80\\%$ earns 3pts\n",
    "- $80\\%$ to $90\\%$ earns 3pts more (6pts total)\n",
    "- $90\\%$+ earns 2pts more (8pts total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUSAXVGPm86l"
   },
   "source": [
    "#### Train your own CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCpEenFbm86m",
    "outputId": "fbbae3e9-c9b5-4dd0-ba15-b095678e07a0"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# Train the model\n",
    "\n",
    "from cnn import CNN\n",
    "\n",
    "net = CNN()\n",
    "batch_size, epochs, init_lr = net.get_vars()\n",
    "\n",
    "def lr_scheduler(epoch):\n",
    "    new_lr = init_lr * 0.9 ** epoch\n",
    "    print(\"Learning rate:\", new_lr)\n",
    "    return new_lr\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_scheduler)],\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    initial_epoch=0, \n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Examine accuracy and loss [2pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should expect to see gradually decreasing loss and gradually increasing accuracy. Examine loss and accuracy by running the cell below, no editing is necessary. Having appropriate looking loss and accuracy plots will earn you the last 2pts for your convolutional net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0dD-7Edm86o",
    "outputId": "dd9af087-5681-4d2c-f080-31bad8ed4c43"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy and loss\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_pred_prob = np.max(y_pred, axis=1)\n",
    "y_gt_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "plt.figure(figsize=(8, 7))\n",
    "plt.imshow(confusion_matrix(y_gt_classes, y_pred_classes))\n",
    "plt.title('Confusion matrix', fontsize=16)\n",
    "plt.xticks(np.arange(10), fashion_classes, rotation=90, fontsize=12)\n",
    "plt.yticks(np.arange(10), fashion_classes, fontsize=12)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Exploring Deep CNN Architectures [3pts] (Bonus for all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network you have produced is rather simple relative to many of those used in industry and research. Researchers have worked to make CNN models deeper and deeper over the past years in an effort to gain higher accuracy in predictions. While your model is only a handful of layers deep, some state of the art deep architectures may include up to 150 layers. However, this process has not been without challenges. \n",
    "\n",
    "One such problem is the problem of the vanishing gradient. The weights of a neural network are updated using the backpropagation algorithm. The backpropagation algorithm makes a small change to each weight in such a way that the loss of the model decreases. Using the chain rule, we can find this gradient for each weight. But, as this gradient keeps flowing backwards to the initial layers, this value keeps getting multiplied by each local gradient. Hence, the gradient becomes smaller and smaller, making the updates to the initial layers very small, increasing the training time considerably.\n",
    "\n",
    "Many tactics have been used in an effort to solve this problem. One architecture, named ResNet, solves the vanishing gradient problem in a unique way. ResNet was developed at Microsoft Research to find better ways to train deep networks. Take a moment to explore how ResNet tackles the vanishing gradient problem by reading the original research paper here: https://arxiv.org/pdf/1512.03385.pdf (also included as PDF in papers directory). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** In your own words, explain how ResNet addresses the vanishing gradient problem in 1-2 sentences below: (Please type answers directly in the cell below.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FxKE3QN2yO6"
   },
   "source": [
    "## 3: Random Forests [50pts] <span style=\"color:blue\">**[P]**</span> <span style=\"color:green\">**[W]**</span>\n",
    "\n",
    "**NOTE**: Please use sklearn's DecisionTreeClassifier in your Random Forest implementation.\n",
    "[You can find more details about this classifier here.](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zP6DnH62yO9"
   },
   "source": [
    "### 3.1 Random Forest Implementation (35 pts) <span style=\"color:blue\">**[P]**</span>\n",
    "\n",
    "The decision boundaries drawn by decision trees are very sharp, and fitting a decision tree of unbounded depth to a list of examples almost inevitably leads to **overfitting**. In an attempt to decrease the variance of a decision tree, we're going to use a technique called 'Bootstrap Aggregating' (often abbreviated 'bagging'). This stems from the idea that a collection of weak learners can learn decision boundaries as well as a strong learner. This is commonly called a Random Forest.\n",
    "\n",
    "We can build a Random Forest as a collection of decision trees, as follows:\n",
    "\n",
    "1. For every tree in the random forest, we're going to \n",
    "\n",
    "    a) Subsample the examples with replacement. Note that in this question, the size of the subsample data is equal to the original dataset. \n",
    "    \n",
    "    b) From the subsamples in part a, choose attributes at random without replacement to learn on in accordance with a provided attribute subsampling rate. Based on what it was mentioned in the class, we randomly pick features in each split. We use a more general approach here to make the programming part easier. Let's randomly pick some features (70% percent of features) and grow the tree based on the pre-determined randomly selected features. Therefore, there is no need to find random features in each split.\n",
    "    \n",
    "    c) Fit a decision tree to the subsample of data we've chosen to a certain depth.\n",
    "    \n",
    "Classification for a random forest is then done by taking a majority vote of the classifications yielded by each tree in the forest after it classifies an example.\n",
    "\n",
    "In RandomForest Class, \n",
    "1. X is assumed to be a matrix with num_training rows and num_features columns where num_training is the\n",
    "number of total records and num_features is the number of features of each record. \n",
    "\n",
    "2. y is assumed to be a vector of labels of length num_training.\n",
    "\n",
    "**NOTE:** Lookout for TODOs for the parts that needs to be implemented. If you receive any ``SettingWithCopyWarning`` warnings from the Pandas library, you can safely ignore them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8E74hGIm86t"
   },
   "source": [
    "### 3.2 Hyperparameter Tuning with a Random Forest (5pts) <span style=\"color:blue\">**[P]**</span>\n",
    "\n",
    "In machine learning, hyperparameters are parameters that are set before the learning process begins. The max_depth, num_estimators, or max_features variables from 3.1 are examples of different hyperparameters for a random forest model. In this section, you will tune your random forest model on a heart disease to achieve a high accuracy on  determining the likelihood of patient having narrowing arteries.\n",
    "\n",
    "Let's first review the dataset in a bit more detail.\n",
    "\n",
    "#### Dataset Objective\n",
    "\n",
    "Imagine that we are doctors working on a cure for heart disease by using machine learning to categorize patients. We know that narrowing arteries are an early indicator of disease. We are tasked with the responsibility of coming up with a method for determining the likelihood of patient having narrowing arteries. We will then use this information to decide which patients to run further tests on for treatment.\n",
    "\n",
    "After much deliberation amongst the team, you come to a conclusion that we can use past patient data to predict the future occurence of disease. \n",
    "\n",
    "We will use our random forest algorithm from Q3.1 to predict if a patient may have indicators of heart disease.\n",
    "\n",
    "You can find more information on the dataset [here](https://archive.ics.uci.edu/ml/datasets/heart+disease)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYwbegdZm86t"
   },
   "source": [
    "#### Loading the dataset\n",
    "\n",
    "\n",
    "The dataset that the company has collected has the following features:\n",
    "\n",
    "Only 13 features used out of a potential 76 to train. We also use the \"num\" feature as our label we are trying to predict.\n",
    " \n",
    "Inputs:\n",
    "\n",
    "1. (age)       \n",
    "2. (type)       \n",
    "3. (cp) chest pain type\n",
    "4. (trestbps) resting blood pressure (in mm Hg on admission to the hospital)\n",
    "5. (chol) serum cholestoral in mg/dl\n",
    "6. (fbs) (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n",
    "7. (restecg) resting electrocardiographic results:\n",
    "    * Value 0: normal\n",
    "    * Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "    * Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "8. (thalach) maximum heart rate achieved\n",
    "9. (exang) exercise induced angina (1 = yes; 0 = no)\n",
    "10. (oldpeak) ST depression induced by exercise relative to rest\n",
    "11. (slope) the slope of the peak exercise ST segment\n",
    "    * Value 1: upsloping\n",
    "    * Value 2: flat\n",
    "    * Value 3: downsloping\n",
    "12. (ca) number of major vessels (0-3) colored by flourosopy      \n",
    "13. (thal) 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "\n",
    "Output:\n",
    "\n",
    "14. (num) target value:\n",
    "    * 0 means <50% chance of narrowing arteries \n",
    "    * 1 means greater than 50% chance of narrowing arteries\n",
    "    \n",
    "Your random forest model will try to predict this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "preprocessor = preprocessing.LabelEncoder()\n",
    "\n",
    "data_train = pd.read_csv(\"./data/heart_disease_cleaveland_train.csv\")\n",
    "data_test = pd.read_csv(\"./data/heart_disease_cleaveland_test.csv\")\n",
    "\n",
    "X_train = data_train.drop(columns = 'num')\n",
    "y_train = data_train['num']\n",
    "y_train = y_train.to_numpy()\n",
    "y_train[y_train > 1] = 1\n",
    "X_test = data_test.drop(columns = 'num')\n",
    "X_test = np.array(X_test)\n",
    "y_test = data_test['num']\n",
    "y_test = y_test.to_numpy()\n",
    "y_test[y_test > 1] = 1\n",
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "assert X_train.shape == (200, 13)\n",
    "assert y_train.shape == (200,)\n",
    "assert X_test.shape == (98, 13)\n",
    "assert y_test.shape == (98,)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlxXUpNE2yPA"
   },
   "source": [
    "In the following codeblock, train your random forest model with different values for max_depth, n_estimators, or max_features and evaluate each model on the held-out test set. Try to choose a combination of hyperparameters that maximizes your prediction accuracy on the test set (aim for 75%+). \n",
    "\n",
    "Once you are satisfied with your chosen parameters, change the values for ```max_depth```, ```n_estimators```, and ```max_features``` in the ```select_hyperparameters()``` function of your RandomForest class in ```random_forest.py``` to your chosen values, and then submit this file to Gradescope. You must achieve at least a **75% accuracy** against the test set in Gradescope to receive full credit for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "6n8GGVU7tYGh",
    "outputId": "4a83b962-d917-4a53-9dc8-2681735d9396"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5983298230fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mrandom_forest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstudent_random_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOOB_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO: \n",
    "n_estimators defines how many decision trees are fitted for the random forest.\n",
    "max_depth defines a stop condition when the tree reaches to a certain depth.\n",
    "max_features controls the percentage of features that are used to fit each decision tree.\n",
    "\n",
    "Tune these three parameters to achieve a better accuracy. While you can use the provided test set to \n",
    "evaluate your implementation, you will need to obtain 75% on the test set to receive full credit \n",
    "for this section.\n",
    "\"\"\"\n",
    "from random_forest import RandomForest\n",
    "import sklearn.ensemble\n",
    "\n",
    "################# DO NOT CHANGE THIS RANDOM SEED ####################\n",
    "student_random_seed = 4641 + 7641\n",
    "#####################################################################\n",
    "\n",
    "################# CHANGE THESE VALUES ###############################\n",
    "n_estimators = 1 #Hint: Consider values between 5-12.\n",
    "max_depth = 1 # Hint: Consider values betweeen 3-12.\n",
    "max_features = 0.1 # Hint: Consider values betweeen 0.6-1.0.\n",
    "#####################################################################\n",
    "\n",
    "random_forest = RandomForest(n_estimators, max_depth, max_features, random_seed=student_random_seed)\n",
    "random_forest.fit(X_train, y_train)\n",
    "    \n",
    "accuracy=random_forest.OOB_score(X_test, y_test)\n",
    "    \n",
    "print(\"accuracy: %.4f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DON'T FORGET**: Once you are satisfied with your chosen parameters, change the values for ```max_depth```, ```n_estimators```, and ```max_features``` in the ```select_hyperparameters()``` function of your RandomForest class in ```random_forest.py``` to your chosen values, and then submit this file to Gradescope. You must achieve at least a **75% accuracy** against the test set in Gradescope to receive full credit for this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQ3Urx3Em86y"
   },
   "source": [
    "### 3.3 Plotting Feature Importance (5pts) <span style=\"color:green\">**[W]**</span>\n",
    "\n",
    "While building tree-based models, it's common to quantify how well splitting on a particular feature in a decision tree helps with predicting the target label in a dataset. Machine learning practicioners typically use \"Gini importance\", or the (normalized) total reduction in entropy brought by that feature to evaluate how important that feature is for predicting the target variable. \n",
    "\n",
    "Gini importance is typically calculated as the reduction in entropy from reaching a split in a decision tree weighted by the probability of reaching that split in the decision tree. Sklearn internally computes the probability for reaching a split by finding the total number of samples that reaches it during the training phase divided by the total number of samples in the dataset. This weighted value is our feature importance.\n",
    "\n",
    "Let's think about what this metric means with an example. A high probabiity of reaching a split on \"Age\" in a decision tree trained on our patient dataset (many samples will reach this split for a decision) and a large reduction in entropy from splitting on \"Age\" will result in a high feature importance value for \"Age\". This could mean \"Age\" is a very important feature for predicting a patients probability of disease. On the other hand, a low probability of reaching a split on \"Cholesterol (chol)\" in a decision tree (few samples will reach this split for a decision) and a low reduction in entropy from splitting on \"Cholesterol (chol)\" will result in a low feature importance value. This could mean \"Cholesterol (chol)\" is not a very informative feature for predicting a patients probability of disease in our decision tree. **Thus, the higher the feature importance value, the more important the feature is to predicting the target label.**\n",
    "\n",
    "Fortunately for us, fitting a sklearn.DecisionTreeClassifier to a dataset auomatically computes the Gini importance for every feature in the decision tree and stores these values in a **feature_importances_** variable. [Review the docs for more details on how to access this variable](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.feature_importances_)\n",
    "\n",
    "In the function below, display a bar plot that shows the feature importance values for at least one decision tree in your tuned random forest from Q3.2, and briefly comment on whether any features have noticeably higher / or lower importance weights than others. **Please also sort the bars in descending order.** You can also remove any features that have a feature importance of zero.\n",
    "\n",
    "[Note that there isn't a \"correct\" answer here. We simply want you to investigate how different features in your random forest contribute to predicting the target variable].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "irV3hL6mm86z",
    "outputId": "30612200-e1ff-4c2a-c367-bf643244b0cb",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Complete plot_feature_importance() in random_forest.py\n",
    "\n",
    "random_forest.plot_feature_importance(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Improvement (5pts) <span style=\"color:green\">**[W]**</span>\n",
    "\n",
    "For this question, we only ask that the Random Forest model have an accuracy of at least 75%. In the real world, we would not be satisified with this accuracy and would most likely not immediately deploy this model to identify narrowing arteries. \n",
    "\n",
    "Please answer the following two questions:\n",
    "1. What are some potential causes for why a Random Forest decision tree model may not produce high accuracies?\n",
    "2. What are some ways to improve on these potential causes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1udwVq0PVFz"
   },
   "source": [
    "\n",
    "\n",
    "## 4: SVM (30 Pts) Bonus of all <span style=\"color:green\">**[W]**</span> <span style=\"color:blue\">**[P]**</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FG6jrvc_m861"
   },
   "source": [
    "### 4.1 Fitting an SVM classifier by hand (20 Pts) <span style=\"color:green\">**[W]**</span>\n",
    "\n",
    "Consider a dataset with the following points in 2-dimensional space:\n",
    "\n",
    "| $$x_1$$ | $$x_2$$ | $$y$$ |\n",
    "| --- | --- | --- |\n",
    "| 0 | 0 | -1 |\n",
    "| 0 | 2 | -1 |\n",
    "| 2 | 0 | -1 |\n",
    "| 2 | 2 | 1 |\n",
    "| 4 | 0 | 1 |\n",
    "| 4 | 4 | 1 |\n",
    "\n",
    "Here, $x_1$ and $x_2$ are features and $y$ is the label.\n",
    "\n",
    "The max margin classifier has the formulation,\n",
    "\n",
    "$$\\min{||\\mathbf{\\theta}||^2} $$\n",
    "\n",
    "$$s.t.\\ y_i(\\mathbf{x_i} \\mathbf{\\theta} + b) â‰¥ 1 \\ \\ \\ \\ \\forall \\ i$$\n",
    "\n",
    "**Hint:** $\\mathbf{x_i}$ are the suppport vectors. Margin is equal to $\\frac{1}{||\\mathbf{\\theta}||}$ and full margin is equal to $\\frac{2}{||\\mathbf{\\theta}||}$. You might find it useful to plot the points in a 2D plane. When calculating the $\\theta$ you don't need to consider the bias term.\n",
    "\n",
    "(1) Are the points linearly separable? Does adding the point $\\mathbf{x} = (4, 2)$, $y = -1$ change the separability? (2 pts)\n",
    "\n",
    "(2) According to the max-margin formulation, find the separating hyperplane. Do not consider the new point from part 1 in your calculations for this current question or subsequent parts. (You should give some kind of explanation or calculation on how you found the hyperplane.) (4 pts)\n",
    "\n",
    "(3) Find a vector parallel to the optimal vector $\\mathbf{\\theta}$. (4 pts)\n",
    "\n",
    "(4) Calculate the value of the margin (single-sided) achieved by this $\\mathbf{\\theta}$? (4 pts)\n",
    "\n",
    "(5) Solve for $\\mathbf{\\theta}$, given that the margin is equal to $1/||\\mathbf{\\theta}||$. (4 pts)\n",
    "\n",
    "(6) If we remove one of the points from the original data the SVM solution might change. Find all such points which change the solution. (2 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NacpSq-Tm862"
   },
   "source": [
    "### 4.2 Feature Mapping (10 Pts) <span style=\"color:blue\">**[P]**</span>\n",
    "\n",
    "Let's look at a dataset where the datapoint can't be classified with a good accuracy using a linear classifier. Run the below cell to generate the dataset.\n",
    "\n",
    "We will also see what happens when we try to fit a linear classifier to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "LmyYQFamm862",
    "outputId": "2ab03801-ca5f-4f98-ffdf-a1ba1aa38f39"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "# Generate dataset\n",
    "\n",
    "random_state = 1\n",
    "\n",
    "X_1 = np.random.uniform(size=(100, 2))\n",
    "y_1 = np.zeros((100,)) - 1\n",
    "\n",
    "X_2 = np.random.uniform(size=(100, 2))\n",
    "X_2[:, 0] = X_2[:, 0] + 1.0\n",
    "y_2 = np.ones((100,))\n",
    "\n",
    "X_3 = np.random.uniform(size=(100, 2))\n",
    "X_3[:, 1] = X_3[:, 1] + 1.0\n",
    "y_3 = np.ones((100,))\n",
    "\n",
    "X_4 = np.random.uniform(size=(100, 2))\n",
    "X_4[:, 0] = X_4[:, 0] + 1.0\n",
    "X_4[:, 1] = X_4[:, 1] + 1.0\n",
    "y_4 = np.zeros((100,)) - 1\n",
    "\n",
    "X = np.concatenate([X_1, X_2, X_3, X_4], axis=0)\n",
    "y = np.concatenate([y_1, y_2, y_3, y_4], axis=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=random_state)\n",
    "\n",
    "f, ax = plt.subplots(nrows=1, ncols=1,figsize=(5,5))\n",
    "plt.scatter(X[:, 0], X[:, 1], c = y, marker = '.') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eaVoa1J-m865"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "def visualize_decision_boundary(X, y, feature_new=None, h=0.02):\n",
    "    '''\n",
    "    You don't have to modify this function\n",
    "    \n",
    "    Function to vizualize decision boundary\n",
    "    \n",
    "    feature_new is a function to get X with additional features\n",
    "    '''\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx_1, xx_2 = np.meshgrid(np.arange(x1_min, x1_max, h),\n",
    "                         np.arange(x2_min, x2_max, h))\n",
    "\n",
    "    if X.shape[1] == 2:\n",
    "        Z = svm_cls.predict(np.c_[xx_1.ravel(), xx_2.ravel()])\n",
    "    else:\n",
    "        X_conc = np.c_[xx_1.ravel(), xx_2.ravel()]\n",
    "        X_new = feature_new(X_conc)\n",
    "        Z = svm_cls.predict(X_new)\n",
    "    Z = Z.reshape(xx_1.shape)\n",
    "    \n",
    "    f, ax = plt.subplots(nrows=1, ncols=1,figsize=(5,5))\n",
    "    plt.contourf(xx_1, xx_2, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)\n",
    "    plt.xlabel('X_1')\n",
    "    plt.ylabel('X_2')\n",
    "    plt.xlim(xx_1.min(), xx_1.max())\n",
    "    plt.ylim(xx_2.min(), xx_2.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "ZJfVwgE2m867",
    "outputId": "7f5cf1c7-bc5e-49d9-e8a4-1a38145d8b11"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "# Try to fit a linear classifier to the dataset\n",
    "\n",
    "svm_cls = svm.LinearSVC()\n",
    "svm_cls.fit(X_train, y_train)\n",
    "y_test_predicted = svm_cls.predict(X_test)\n",
    "\n",
    "print(\"Accuracy on test dataset: {}\".format(accuracy_score(y_test, \n",
    "                                                           y_test_predicted)))\n",
    "\n",
    "visualize_decision_boundary(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuShu_ECm869"
   },
   "source": [
    "We can see that we need a non-linear boundary to be able to successfully classify data in this dataset. By mapping the current feature x to a higher space with more features, linear SVM could be performed on the features in the higher space to learn a non-linear decision boundary. In the function below add additional features which can help classify in the above dataset. After creating the additional features use code in the further cells to see how well the features perform on the test set. \n",
    "\n",
    "**Note:** You should get a test accuracy above 90%\n",
    "\n",
    "**Hint:** Think of the shape of the decision boundary that would best separate the above points. What additional features could help map the linear boundary to the non-linear one? Look at [this](https://xavierbourretsicotte.github.io/Kernel_feature_map.html) for a detailed analysis of doing the same for points separable with a circular boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "from feature import create_nl_feature\n",
    "\n",
    "X_new = create_nl_feature(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "VaUahNX9m87B",
    "outputId": "c4624aea-2dd0-41ad-e844-1ecfdb1e8de9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "# Fit to the new features and vizualize the decision boundary\n",
    "# You should get more than 90% accuracy on test set\n",
    "\n",
    "svm_cls = svm.LinearSVC()\n",
    "svm_cls.fit(X_train, y_train)\n",
    "y_test_predicted = svm_cls.predict(X_test)\n",
    "\n",
    "print(\"Accuracy on test dataset: {}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "\n",
    "visualize_decision_boundary(X_train, y_train, create_nl_feature)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW4_FALL2020_solutions.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
